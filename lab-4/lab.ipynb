{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4\n",
    "\n",
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model f1 score: 98.577\n",
      "(501, 3, 485, 11)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\IST820\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model f1 score: 98.231\n",
      "(511, 16, 472, 1)\n",
      "\n",
      "Model f1 score: 95.490\n",
      "(467, 1, 487, 45)\n",
      "\n",
      "Model f1 score: 98.683\n",
      "(500, 1, 487, 12)\n",
      "\n",
      "Completed 1/1\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 6\n",
    "\n",
    "\n",
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_actual[i][1] == 1 and y_pred[i][1] >= 0.5:\n",
    "            TP += 1\n",
    "        if y_pred[i][1] >= 0.5 and y_actual[i][1] == 0:\n",
    "            FP += 1\n",
    "        if y_actual[i][1] == 0 and y_pred[i][1] < 0.5:\n",
    "            TN += 1\n",
    "        if y_pred[i][1] <= 0.5 and y_actual[i][1] == 1:\n",
    "            FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "\n",
    "def build_model(hidden_tensor, kernel_size, dropout_rate):\n",
    "    inputs = tf.keras.layers.Input(shape=(WINDOW_SIZE, 32,8), name='Input')\n",
    "\n",
    "    y = tf.keras.layers.Conv2D(filters=hidden_tensor[0], kernel_size=kernel_size[0], padding='same', activation='relu', name='Hidden0')(inputs)\n",
    "    y = tf.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=(3, 3), padding='same', name='Pooling0')(y)\n",
    "    y = tf.keras.layers.Flatten(name='Flatten')(y)\n",
    "    y = tf.keras.layers.Dense(hidden_tensor[1], activation='relu', name='Dense')(y)\n",
    "    y = tf.keras.layers.Dropout(dropout_rate, name='Dropout')(y)\n",
    "\n",
    "    probs = tf.keras.layers.Dense(2, activation='softmax', name='Output')(y)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, probs, name='classifier4')\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "    else:\n",
    "        tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "        tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "\n",
    "    # training epochs and batch size\n",
    "    n_epoch = 3\n",
    "    n_batch = 50\n",
    "\n",
    "    # model hyper-parameters to tune\n",
    "    hidden_tensors = [[4,4]]\n",
    "    kernel_sizes = [[(3, 3)]]\n",
    "    dropout_rates = [0.25]\n",
    "\n",
    "    # open file in text mode for writing training log\n",
    "    n = 0\n",
    "    while(os.path.isfile(os.path.join(\".\",\"Model\", \"training-log-\"+('%.2d' % (n))+\".txt\"))):\n",
    "        n += 1\n",
    "    fi = open(os.path.join(\".\",\"Model\",\"training-log-\"+('%.2d' % (n))+\".txt\"), 'w')\n",
    "\n",
    "    # record output direction\n",
    "    # fiout means output to log file\n",
    "    # sys.stdout means output to console\n",
    "    fiout = fi\n",
    "    oldStdOut = sys.stdout\n",
    "\n",
    "    k = 0\n",
    "    # by the following line, the console output is directed to be written to the log file\n",
    "    sys.stdout = fiout\n",
    "\n",
    "\n",
    "    # load data\n",
    "    X=np.load(os.path.join(\".\",\"Data\",\"X.npy\"),allow_pickle=True)\n",
    "    Y=np.load(os.path.join(\".\",\"Data\",\"Y.npy\"),allow_pickle=True)\n",
    "\n",
    "    # shuffle loaded data, and split training and test set by 4:1\n",
    "    X, Y = shuffle(X, Y, random_state=1)\n",
    "    X_train=X[:4000]\n",
    "    X_test=X[4000:5000]\n",
    "    Y_train=Y[:4000]\n",
    "    Y_test=Y[4000:5000]\n",
    "\n",
    "    for hidden_tensor in hidden_tensors:\n",
    "        for kernel_size in kernel_sizes:\n",
    "            for dropout_rate in dropout_rates:\n",
    "                # log training info\n",
    "                fi.writelines([\n",
    "                    \"*********************************************************************************************************************************************\\r\",\n",
    "                    \"model parameter set \"+str(k)+\"\\r\",\n",
    "                    \"\\r\"\n",
    "                ])  # \"\\n\" is automatically append to the end of each line\n",
    "\n",
    "                # NN: 4-fold cross validation\n",
    "                acc = []\n",
    "                TPs = []\n",
    "                FPs = []\n",
    "                TNs = []\n",
    "                FNs = []\n",
    "                for i in range(4):\n",
    "                    print(\n",
    "                        \"################################################################################################################################\", end=\"\\n\")\n",
    "                    print(\"fold \"+str(i+1)+\"/\"+str(4), end=\"\\n\")\n",
    "                    # prepare data\n",
    "                    tmp_train_x = X_train.tolist()\n",
    "                    tmp_train_y = Y_train.tolist()\n",
    "                    start = i*len(X_train)//4\n",
    "                    end = (i+1)*len(X_train)//4\n",
    "                    del(tmp_train_x[start:end])\n",
    "                    del(tmp_train_y[start:end])\n",
    "                    tmp_train_x = np.array(tmp_train_x)\n",
    "                    tmp_train_y = np.array(tmp_train_y)\n",
    "                    tmp_val_x = X_train[start:end]\n",
    "                    tmp_val_y = Y_train[start:end]\n",
    "\n",
    "                    # build model\n",
    "                    model = build_model(hidden_tensor, kernel_size, dropout_rate)\n",
    "                    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[F1Score(num_classes=2)])\n",
    "                    print(model.summary())\n",
    "\n",
    "                    # start training\n",
    "                    model.fit(tmp_train_x, tmp_train_y, validation_data=(tmp_val_x, tmp_val_y), epochs=n_epoch, batch_size=n_batch)\n",
    "\n",
    "                    # evaluate\n",
    "                    scores = model.evaluate(X_test, Y_test, batch_size=n_batch, verbose=0)\n",
    "                    Y_predict = model.predict(X_test,batch_size=n_batch)\n",
    "                    Mat = perf_measure(Y_test, Y_predict)\n",
    "                    acc.append(scores[1][0])\n",
    "\n",
    "                    sys.stdout = oldStdOut\n",
    "                    print(\"Model f1 score: %.3f\" % (scores[1][0]*100))\n",
    "                    print(Mat)\n",
    "                    print()\n",
    "                    sys.stdout = fiout\n",
    "                    print(\"Model f1 score: %.3f\" % (scores[1][0]*100))\n",
    "                    print(\"(TP, FP, TN, FN)\"+str(Mat))\n",
    "                    model.save(os.path.join(\".\",\"Model\", \"classifier-\"+str(n)+\"-\"+str(k)+\"-\"+str(i)+\".h5\"))\n",
    "                    TPs.append(Mat[0])\n",
    "                    FPs.append(Mat[1])\n",
    "                    TNs.append(Mat[2])\n",
    "                    FNs.append(Mat[3])\n",
    "\n",
    "                # summarize performance across four folds\n",
    "                print(\"######################################################################################################\", end=\"\\n\")\n",
    "                print(\"all folds done\", end=\"\\n\")\n",
    "                print(\"average f1 score: %.3f\" %\n",
    "                        (100*sum(acc)/len(acc)), end=\"\\n\")\n",
    "                print(\"average confusion matrix (TP,FP,TN.FN): (%.2f, %.2f, %.2f, %.2f)\" % (\n",
    "                    (sum(TPs)/len(TPs)), (sum(FPs)/len(FPs)), (sum(TNs)/len(TNs)), (sum(FNs)/len(FNs))))\n",
    "                print(\"average false positive rate: %.3f%%\" %\n",
    "                        (100*sum(FPs)/(sum(FPs)+sum(TNs))))\n",
    "                print(\"average false negative rate: %.3f%%\" %\n",
    "                        (100*sum(FNs)/(sum(FNs)+sum(TPs))))\n",
    "                sys.stdout = oldStdOut\n",
    "                print(\"Completed %d/%s\" % (k+1, len(hidden_tensors)*len(kernel_sizes)*len(dropout_rates)))\n",
    "                sys.stdout = fiout\n",
    "                k += 1\n",
    "\n",
    "sys.stdout = oldStdOut\n",
    "fi.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "```py\n",
    "# load data\n",
    "X=np.load(os.path.join(\"..\",\"Data\",\"X.npy\"),allow_pickle=True)\n",
    "Y=np.load(os.path.join(\"..\",\"Data\",\"Y.npy\"),allow_pickle=True)\n",
    "```\n",
    "\n",
    "This uses the numpy library to load the two data files from the data directory\n",
    "\n",
    "## Shuffling Data\n",
    "\n",
    "```py\n",
    "# shuffle loaded data, and split training and test set by 4:1\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "X_train=X[:4000]\n",
    "X_test=X[4000:5000]\n",
    "Y_train=Y[:4000]\n",
    "Y_test=Y[4000:5000]\n",
    "```\n",
    "\n",
    "This creates testing and training subsets of the data in a 4:1 ratio. The model will be trained on the first set, and tested on the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each row of the matrix contains 32 integers.\n",
      "The matrix contains 6 rows.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X=np.load(os.path.join(\".\",\"Data\",\"X.npy\"),allow_pickle=True)\n",
    "Y=np.load(os.path.join(\".\",\"Data\",\"Y.npy\"),allow_pickle=True)\n",
    "\n",
    "# Assuming each sample in X is a matrix, let's check the shape of the first sample\n",
    "sample_shape = X[5].shape\n",
    "\n",
    "# Get the number of integers per row (columns)\n",
    "num_integers_per_row = sample_shape[1]\n",
    "\n",
    "# Get the number of rows in the matrix\n",
    "num_rows_in_matrix = sample_shape[0]\n",
    "\n",
    "# Now, print the completed answer\n",
    "print(f\"Each row of the matrix contains {num_integers_per_row} integers.\")\n",
    "print(f\"The matrix contains {num_rows_in_matrix} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
